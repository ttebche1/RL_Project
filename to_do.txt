# Class:
# - Add particle filter for target estimation
# - Make the agent move at constant velocity
# - Update model to angle-based
# - Add dropped comms: 10% drop rate, and If distance between agent and target greater than 0.9 (normalized to 1km), agent does not receive range measurement
#
# Analyses:
# - Added estimator for agent position and corrected observation space
# - Different parameters and reward - theirs don't even train
#
# Later:
# - Add moving target w/ trailing
# - Add baseline comparison
# - Add 3D environment (depth)
# - Add complex comms things such as doppler
# - Turn it into a whale problem!
# - Add a more complex current model
# - Minimize power expended rather than distance
#
# Multi-agents:
# - Add multiple agents
# - Remove full observability, but they know each other's distance to target
# - Try no comms
# - Add a larger search space than 2km
# - Try different multi-RL algorithms
#
# Speed:
# - Does prompting it with a non-ML search algorithm help?
# - Curriculum training 
# - Automatically tune hyperparameters
